\documentclass[11pt,a4paper]{article}

% ----------------------------------------------------
% PACKAGES ESSENTIELS
% ----------------------------------------------------
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{siunitx}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{float}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{titlesec}
\usepackage[strict]{changepage}
\usepackage{framed}
\usepackage{hyperref}

% ----------------------------------------------------
% PARAMÈTRES DE MISE EN PAGE
% ----------------------------------------------------
\geometry{margin=2.5cm}
\setlength{\parskip}{0.5em}
\setlength{\parindent}{0pt}
\setlength{\headheight}{13.6pt}
\addtolength{\topmargin}{-1.6pt}
\setlength{\emergencystretch}{2em}

% ----------------------------------------------------
% COULEURS ENSTA
% ----------------------------------------------------
\definecolor{enstaBleuFonce}{HTML}{003366}
\definecolor{enstaBleuClair}{HTML}{0073CF}
\definecolor{formalshade}{rgb}{0.95,0.95,1}

% ----------------------------------------------------
% CONFIGURATION DES LIENS
% ----------------------------------------------------
\hypersetup{
    colorlinks=true,
    linkcolor=enstaBleuFonce,
    urlcolor=blue,
    citecolor=gray
}

% ----------------------------------------------------
% STYLE DES SECTIONS
% ----------------------------------------------------
\titleformat{\section}[block]
  {\normalfont\Large\bfseries\color{enstaBleuFonce}}
  {\thesection}{1em}{}
  [\vspace{0.3em}\titlerule\color{enstaBleuFonce}\vspace{0.3em}]

\titleformat{\subsection}
  {\normalfont\large\bfseries\color{enstaBleuClair}}
  {\thesubsection}{1em}{}

\titleformat{\subsubsection}
  {\normalfont\normalsize\bfseries\color{black!70}}
  {\thesubsubsection}{1em}{}

% ----------------------------------------------------
% EN-TÊTES ET PIEDS DE PAGE
% ----------------------------------------------------
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{École Nationale des techniques avancées}
\fancyhead[R]{OS202}
\fancyfoot[C]{\thepage}

% ----------------------------------------------------
% ENVIRONNEMENT FORMAL (ENCADRÉ)
% ----------------------------------------------------
\newenvironment{formal}{%
\def\FrameCommand{%
  \hspace{1pt}%
  {\color{enstaBleuFonce}\vrule width 2pt}%
  {\color{formalshade}\vrule width 4pt}%
  \colorbox{formalshade}%
}%
\MakeFramed{\advance\hsize-\width\FrameRestore}%
\noindent\hspace{-4.55pt}%
\begin{adjustwidth}{}{7pt}%
\vspace{4pt}%
}{%
\vspace{4pt}\end{adjustwidth}\endMakeFramed%
}

% ----------------------------------------------------
% DÉBUT DU DOCUMENT
% ----------------------------------------------------
\begin{document}

% ====================================================
% PAGE DE COUVERTURE
% ====================================================
\begin{titlepage}
    \centering
    \vspace*{3.5cm}

    \includegraphics[width=0.6\textwidth]{imgs/logo_ensta_2025.png}

    \vspace{0.6cm}
    {\Large OS202 -- Systèmes Parallèles \par}
    \vspace{0.2cm}
    {\huge\bfseries TD2 : Ensemble de Mandelbrot et Produit Matrice-Vecteur \par}
    \vspace{2.8cm}
    {\Large MENESES GAMBOA Carlos \par}
    \vfill
    École Nationale des techniques avancées\\
    Février 2026\par
\end{titlepage}

% ====================================================
% TABLE DES MATIÈRES
% ====================================================
\newpage
\tableofcontents
\newpage

% ====================================================
% RÉSUMÉ
% ====================================================
\section{Résumé}
Ce rapport présente la parallélisation MPI de l'ensemble de Mandelbrot selon trois stratégies (blocs contigus, distribution cyclique, maître-esclave) ainsi que le produit matrice-vecteur parallèle par colonnes et par lignes. Une analyse théorique des lois d'Amdahl et Gustafson complète l'étude.

% ====================================================
% MACHINE UTILISÉE
% ====================================================
\section{Machine utilisée}

\begin{table}[H]
  \centering
  \small
  \caption{Caractéristiques de la machine.}
  \label{tab:pc-specs}
  \begin{tabular}{@{}ll@{}}
    \toprule
    Champ & Valeur \\
    \midrule
    Architecture & x86\_64 \\
    Model name & 11th Gen Intel Core i5-1135G7 @ 2.40GHz \\
    CPU(s) & 8 \\
    Thread(s) per core & 2 \\
    Core(s) per socket & 4 \\
    L1d / L1i cache & 192 KiB / 128 KiB \\
    L2 cache & 5 MiB \\
    L3 cache & 8 MiB \\
    Hypervisor & Microsoft (WSL2) \\
    \bottomrule
  \end{tabular}
\end{table}


% ====================================================
% ENSEMBLE DE MANDELBROT
% ====================================================
\section{Parallélisation de l'ensemble de Mandelbrot}

L'ensemble de Mandelbrot est défini par la suite récursive :
\[
\left\{
\begin{array}{l}
    z_{0} = 0 \\
    z_{n+1} = z_{n}^{2} + c
\end{array}
\right.
\]
où $c$ est un paramètre complexe. Si $|z_N| > 2$ pour un certain $N$, la suite diverge. On fixe $N_{\max} = 50$ itérations et une image de $1024 \times 1024$ pixels.

\subsection{Q1 -- Partition par blocs contigus}

Chaque processus calcule un bloc contigu de $H/\texttt{nbp}$ lignes consécutives. Le processus 0 rassemble les résultats via \texttt{gather}.

\begin{table}[H]
  \centering
  \caption{Mandelbrot -- Partition par blocs contigus.}
  \label{tab:mandel-blocs}
  \begin{tabular}{@{}rrrr@{}}
    \toprule
    Processus & Temps (s) & Speedup & Efficacité (\%) \\
    \midrule
    1 & 2.67 & 1.00 & 100.0 \\
    2 & 1.62 & 1.65 & 82.5 \\
    3 & 1.36 & 1.96 & 65.3 \\
    4 & 1.21 & 2.21 & 55.3 \\
    \bottomrule
  \end{tabular}
\end{table}

\textbf{Interprétation :} Le speedup est sous-linéaire car la charge de travail est \emph{déséquilibrée}. Les lignes centrales de l'image (proches du cardioïde de Mandelbrot) nécessitent beaucoup plus d'itérations que les lignes extérieures qui divergent rapidement. Ainsi, le processus qui hérite des lignes centrales devient un goulot d'étranglement.


\subsection{Q2 -- Distribution cyclique}

Pour équilibrer la charge, on distribue les lignes de façon cyclique : le processus $p$ calcule les lignes $p, p+\texttt{nbp}, p+2\cdot\texttt{nbp}, \ldots$ Cela entrelace les lignes ``faciles'' et ``difficiles'' entre tous les processus.

\begin{table}[H]
  \centering
  \caption{Mandelbrot -- Distribution cyclique.}
  \label{tab:mandel-cyclic}
  \begin{tabular}{@{}rrrr@{}}
    \toprule
    Processus & Temps (s) & Speedup & Efficacité (\%) \\
    \midrule
    1 & 2.67 & 1.00 & 100.0 \\
    2 & 1.80 & 1.48 & 74.0 \\
    3 & 1.44 & 1.85 & 61.7 \\
    4 & 1.38 & 1.93 & 48.3 \\
    \bottomrule
  \end{tabular}
\end{table}

\textbf{Comparaison :} De manière surprenante, les deux stratégies donnent des résultats \emph{similaires} (speedup $\sim$2 avec 4 processus). Cela s'explique par les \textbf{optimisations géométriques} implémentées dans le code :

\begin{itemize}[leftmargin=1.5em]
  \item Détection du cardioïde principal : $|c|^2 < 0.0625$
  \item Détection du bulbe secondaire : $|c+1|^2 < 0.0625$
  \item Test de la cardioïde : évite les itérations pour les points connus comme convergents
\end{itemize}

Ces optimisations permettent de \emph{court-circuiter} le calcul pour les points du centre de l'ensemble (qui normalement nécessiteraient 50 itérations). Ainsi, toutes les lignes ont un coût de calcul similaire, et le déséquilibre de charge disparaît.

\textbf{Vérification expérimentale :} En désactivant ces optimisations, on observe une différence significative :

\begin{table}[H]
  \centering
  \small
  \caption{Comparaison avec/sans optimisations géométriques (4 processus).}
  \label{tab:mandel-opt-compare}
  \begin{tabular}{@{}lccc@{}}
    \toprule
    Version & Blocs (s) & Cyclique (s) & Gain cyclique \\
    \midrule
    Avec optimisations & 1.21 & 1.38 & $-14\%$ (plus lent) \\
    Sans optimisations & 2.04 & 1.57 & $+23\%$ (plus rapide) \\
    \bottomrule
  \end{tabular}
\end{table}

\textbf{Conclusion :} Sans optimisations, le cyclique est effectivement 23\% plus rapide grâce à un meilleur équilibrage de charge. Avec optimisations, le déséquilibre disparaît et le cyclique perd son avantage (l'overhead de réordonnancement le rend même légèrement plus lent).

\textbf{Problème potentiel :} Cette stratégie fonctionne bien pour Mandelbrot car les zones de charge élevée sont localisées au centre. Pour d'autres problèmes où la charge est distribuée différemment (par exemple, aléatoirement), la distribution cyclique ne garantirait pas un bon équilibrage.


\subsection{Q3 -- Stratégie maître-esclave (dynamique)}

Le processus 0 (maître) distribue dynamiquement des chunks de lignes aux processus esclaves. Quand un esclave termine un chunk, il en demande un nouveau. Cela permet un équilibrage automatique de la charge.

\begin{table}[H]
  \centering
  \caption{Mandelbrot -- Maître-esclave (chunks de 32 lignes).}
  \label{tab:mandel-dynamic}
  \begin{tabular}{@{}rrrrr@{}}
    \toprule
    Processus & Esclaves & Temps (s) & Speedup$^*$ & Efficacité (\%) \\
    \midrule
    2 & 1 & 3.59 & 0.74 & 74.0 \\
    3 & 2 & 2.07 & 1.29 & 64.5 \\
    4 & 3 & 1.83 & 1.46 & 48.7 \\
    \bottomrule
  \end{tabular}
  
  \footnotesize{$^*$Speedup calculé par rapport au temps séquentiel de 2.67s.}
\end{table}

\textbf{Analyse :} Contrairement aux attentes, la stratégie maître-esclave est \emph{moins performante} que les approches statiques. Cela s'explique par :
\begin{enumerate}[leftmargin=1.5em]
  \item \textbf{Perte d'un processeur :} Le maître ne calcule pas, donc avec 4 processus on n'a que 3 workers.
  \item \textbf{Overhead de communication :} Chaque chunk nécessite 2 messages (envoi de tâche + réception de résultat), soit $\sim$32 aller-retours pour 1024 lignes.
  \item \textbf{Bon équilibrage naturel du cyclique :} Pour Mandelbrot, la distribution cyclique équilibre déjà bien la charge, rendant le dynamique superflu.
\end{enumerate}

\textbf{Conclusion :} La stratégie maître-esclave serait avantageuse pour des problèmes avec une charge très variable et imprévisible (par exemple, temps de calcul variant de 1 à 1000 selon les données). Pour Mandelbrot avec une charge prévisible, les approches statiques sont préférables.


% ====================================================
% PRODUIT MATRICE-VECTEUR
% ====================================================
\section{Produit matrice-vecteur parallèle}

On considère le produit $v = A \cdot u$ où $A$ est une matrice $N \times N$ avec $A_{ij} = (i+j) \mod N + 1$ et $u$ un vecteur de taille $N$. On prend $N = 4800$ (divisible par 1, 2, 3, 4).

\textbf{Note importante :} Pour éviter la contention entre les threads BLAS et les processus MPI, il est essentiel de configurer \texttt{OMP\_NUM\_THREADS=1} \emph{avant} d'importer NumPy.


\subsection{a -- Partition par colonnes}

Chaque processus détient $N_{\text{loc}} = N / \texttt{nbp}$ colonnes de $A$ et la partie correspondante de $u$. Le calcul local produit une contribution partielle au vecteur résultat. Un \texttt{Allreduce} avec \texttt{MPI\_SUM} combine toutes les contributions.

\[
N_{\text{loc}} = \frac{N}{\texttt{nbp}}
\]

\begin{table}[H]
  \centering
  \caption{Produit matrice-vecteur par colonnes ($N=4800$).}
  \label{tab:matvec-col}
  \begin{tabular}{@{}rrrrr@{}}
    \toprule
    Processus & Cómputo (ms) & Comm (ms) & Total (ms) & Speedup \\
    \midrule
    1 & 8.6 & 0.08 & 8.7 & 1.00 \\
    2 & 6.6 & 0.40 & 7.0 & 1.24 \\
    3 & 5.5 & 0.57 & 6.1 & 1.43 \\
    4 & 5.2 & 0.87 & 6.1 & 1.43 \\
    \bottomrule
  \end{tabular}
\end{table}

\textbf{Observation :} Le speedup plafonne à 1.43 car le temps de communication (\texttt{Allreduce} sur un vecteur de taille $N$) augmente avec le nombre de processus, compensant partiellement le gain de calcul.


\subsection{b -- Partition par lignes}

Chaque processus détient $N_{\text{loc}} = N / \texttt{nbp}$ lignes de $A$ et le vecteur $u$ complet. Le calcul local produit directement une partie du vecteur résultat. Un \texttt{Allgather} rassemble toutes les parties.

\[
N_{\text{loc}} = \frac{N}{\texttt{nbp}}
\]

\begin{table}[H]
  \centering
  \caption{Produit matrice-vecteur par lignes ($N=4800$).}
  \label{tab:matvec-row}
  \begin{tabular}{@{}rrrrr@{}}
    \toprule
    Processus & Cómputo (ms) & Comm (ms) & Total (ms) & Speedup \\
    \midrule
    1 & 9.5 & 0.07 & 9.6 & 1.00 \\
    2 & 7.5 & 0.14 & 7.6 & 1.26 \\
    3 & 6.1 & 0.22 & 6.3 & 1.52 \\
    4 & 6.0 & 0.57 & 6.6 & 1.45 \\
    \bottomrule
  \end{tabular}
\end{table}


\subsection{Comparaison des deux approches}

\begin{table}[H]
  \centering
  \caption{Comparaison colonnes vs lignes.}
  \label{tab:matvec-compare}
  \begin{tabular}{@{}lcc@{}}
    \toprule
    Aspect & Par colonnes & Par lignes \\
    \midrule
    Stockage local de $A$ & $N \times N_{\text{loc}}$ & $N_{\text{loc}} \times N$ \\
    Stockage de $u$ & $N_{\text{loc}}$ (partiel) & $N$ (complet) \\
    Résultat local & Contribution partielle (taille $N$) & Partie finale (taille $N_{\text{loc}}$) \\
    Communication & \texttt{Allreduce} (somme de vecteurs $N$) & \texttt{Allgather} (concaténation) \\
    Volume communiqué & $N$ doubles par processus & $N_{\text{loc}}$ doubles par processus \\
    \bottomrule
  \end{tabular}
\end{table}

\textbf{Conclusion :} La partition par lignes est théoriquement plus efficace en communication car \texttt{Allgather} transfère moins de données ($N_{\text{loc}}$ vs $N$ par processus). En pratique, pour des problèmes de cette taille, les différences sont minimes.


% ====================================================
% EXERCICE THÉORIQUE
% ====================================================
\section{Entraînement pour l'examen écrit}

\subsection{Loi d'Amdahl}

Alice a un code où 90\% du temps est parallélisable ($p = 0.9$) et 10\% est séquentiel ($s = 0.1$).

La loi d'Amdahl donne l'accélération maximale :
\[
S(n) = \frac{1}{s + \frac{p}{n}} = \frac{1}{0.1 + \frac{0.9}{n}}
\]

Pour $n \to \infty$ :
\[
\boxed{S_{\max} = \frac{1}{s} = \frac{1}{0.1} = 10}
\]

\textbf{Réponse :} L'accélération maximale est de \textbf{10}.


\subsection{Nombre de nœuds raisonnable}

On cherche $n$ tel que le gain marginal soit acceptable. Calculons l'efficacité $E = S/n$ :

\begin{table}[H]
  \centering
  \caption{Accélération et efficacité selon la loi d'Amdahl.}
  \label{tab:amdahl}
  \begin{tabular}{@{}rrr@{}}
    \toprule
    $n$ (nœuds) & $S(n)$ & Efficacité (\%) \\
    \midrule
    1 & 1.00 & 100.0 \\
    2 & 1.82 & 91.0 \\
    4 & 3.08 & 77.0 \\
    8 & 4.71 & 58.8 \\
    10 & 5.26 & 52.6 \\
    16 & 6.40 & 40.0 \\
    32 & 7.62 & 23.8 \\
    \bottomrule
  \end{tabular}
\end{table}

\textbf{Réponse :} Un nombre raisonnable serait \textbf{8 à 10 nœuds}, où l'on obtient environ 50\% de l'accélération maximale avec une efficacité encore acceptable ($\sim$50--60\%). Au-delà, les ressources sont gaspillées.


\subsection{Loi de Gustafson}

Alice observe une accélération maximale de 4 (au lieu de 10 théorique). D'après la loi d'Amdahl, si l'accélération se sature à 4, cela implique que la fraction séquentielle \emph{effective} est :
\[
s = \frac{1}{S_{\max}} = \frac{1}{4} = 0.25
\]

et que la partie parallélisable vaut :
\[
p = 1 - s = 0.75
\]

Si l'on \textbf{double} maintenant la quantité de données et que l'on suppose une complexité parallèle linéaire, alors la partie parallélisable (le travail « scalable ») est doublée tandis que la partie séquentielle reste approximativement constante. Le nouveau temps séquentiel normalisé devient :
\[
T'_1 = s + 2 \cdot p = 0.25 + 2 \times 0.75 = 1.75
\]

Par conséquent, la nouvelle fraction séquentielle est :
\[
s' = \frac{s}{T'_1} = \frac{0.25}{1.75} = \frac{1}{7} \approx 0.143
\]

En appliquant la loi de Gustafson pour $n$ nœuds :
\[
S_G(n) = n - s'(n-1) = n - \frac{1}{7}(n-1) = \frac{7n - (n-1)}{7} = \frac{6n + 1}{7}
\]

Pour $n$ grand :
\[
\boxed{S_G(n) \approx \frac{6}{7} n \approx 0.857 \, n}
\]

\textbf{Réponse :} En doublant les données, l'accélération maximale suit $S_G(n) = \frac{6n+1}{7}$, soit environ \textbf{85.7\% d'efficacité parallèle} pour un grand nombre de nœuds. Par exemple, avec 8 nœuds : $S_G(8) = \frac{49}{7} = 7$.


% ====================================================
% CONCLUSION GÉNÉRALE
% ====================================================
\section{Conclusion générale}

\begin{itemize}[leftmargin=1.2em]
  \item \textbf{Mandelbrot -- Équilibrage de charge :} La distribution cyclique offre un bon compromis entre simplicité et performance. Le maître-esclave, bien que flexible, introduit un overhead significatif pour ce problème.
  
  \item \textbf{Produit matrice-vecteur :} Les deux partitions (colonnes/lignes) donnent des performances similaires. La partition par lignes est légèrement plus efficace en communication (\texttt{Allgather} vs \texttt{Allreduce}).
  
  \item \textbf{Contention BLAS/MPI :} Il est crucial de limiter les threads BLAS (\texttt{OMP\_NUM\_THREADS=1}) pour éviter la sursouscription avec MPI.
  
  \item \textbf{Lois de scaling :} Amdahl prédit les limites du speedup pour un problème fixe (ici $S_{\max}=10$). Gustafson montre qu'en augmentant la taille du problème, on peut maintenir une bonne efficacité.
\end{itemize}

\end{document}
